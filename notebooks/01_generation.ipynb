{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Cell 1: Imports and Settings","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\nfrom tokenizers import Tokenizer\nimport torch\n\nMODEL_NAME = \"hugohrban/progen2-medium\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Tags and N-terminal fragments for biomass-degrading enzyme families\nTAGS = {\n    \"GH10\": \"<|GH10|>\",\n    \"GH11\": \"<|GH11|>\",\n    \"GH5\": \"<|GH5|>\",\n    \"GH48\": \"<|GH48|>\",\n    \"CE1\": \"<|CE1|>\",\n    \"PL1\": \"<|PL1|>\",\n    \"PL7\": \"<|PL7|>\"\n}\n\nPROMPT_FRAGMENTS = {\n    \"GH10\": \"MSKQSSQASGASRAVYAKYT\",\n    \"GH11\": \"MKYLLPTAAFCLVSCLALAA\",\n    \"GH5\": \"MSKSFVILFSFLSAVTVLAK\",\n    \"GH48\": \"MKFNSRLLISVTLAVAGSSS\",\n    \"CE1\": \"MALQFLLLVVLLLSHQAQA\",\n    \"PL1\": \"MKAVAAIAAVASLAGSVLAE\",\n    \"PL7\": \"MNSTTAIALGAVPAAALTYA\"\n}\n\nMAX_LENGTH = 1024\nSAMPLES_PER_FAMILY = 5\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cell 2: Load Model and Tokenizer\n","metadata":{}},{"cell_type":"code","source":"print(\"Loading model and tokenizer...\")\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_NAME, trust_remote_code=True).to(DEVICE)\ntokenizer = Tokenizer.from_pretrained(MODEL_NAME)\ntokenizer.no_padding()\nprint(\"Model loaded successfully...\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cell 3: Define Sequence Generation Function\n","metadata":{}},{"cell_type":"code","source":"def generate_sequences(tag, seed_fragment, n_samples=5):\n    prompt = f\"MASK_START {tag} {seed_fragment}\"\n    input_ids = tokenizer.encode(prompt).ids\n    input_ids = torch.tensor(input_ids).unsqueeze(0).to(DEVICE)\n\n    generated_sequences = []\n    for _ in range(n_samples):\n        generated = input_ids.clone()\n        with torch.no_grad():\n            for _ in range(MAX_LENGTH - input_ids.size(1)):\n                outputs = model(generated)\n                next_token_logits = outputs.logits[:, -1, :]\n                probs = torch.nn.functional.softmax(next_token_logits, dim=-1)\n                next_token = torch.multinomial(probs, num_samples=1)\n                generated = torch.cat((generated, next_token), dim=1)\n\n                # Optional: break if EOS token is generated\n                if next_token.item() == tokenizer.token_to_id(\"\"):\n                    break\n\n        decoded = tokenizer.decode(generated[0].tolist())\n        generated_sequences.append(decoded)\n\n    return generated_sequences\nprint(\"Generation Function defined successfully...\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cell 4: Generate Sequences for Each Family\n","metadata":{}},{"cell_type":"code","source":"print(\"Starting generation process...\")\n\n\nimport time\n\ndef format_duration(seconds):\n    minutes, seconds = divmod(int(seconds), 60)\n    return f\"{minutes:02d}:{seconds:02d}\"\n\nresults = {}\ntotal_start = time.time()\n\nfor fam, tag in TAGS.items():\n    print(f\"Generating sequences for {fam}...\")\n    fragment = PROMPT_FRAGMENTS[fam]\n\n    start = time.time()\n    sequences = generate_sequences(tag, fragment, SAMPLES_PER_FAMILY)\n    duration = time.time() - start\n\n    print(f\"âœ… {fam} done in {format_duration(duration)} (mm:ss)\")\n    results[fam] = sequences\n\ntotal_end = time.time()\nprint(f\"ðŸ Total generation time: {format_duration(total_end - total_start)} (mm:ss)\")\n\n\nprint(\"Generation completed...\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cell 5: Save Generated Sequences to FASTA File\n\n","metadata":{}},{"cell_type":"code","source":"with open(\"generated_sequences.fasta\", \"w\") as f:\n    for fam, seqs in results.items():\n        for i, seq in enumerate(seqs):\n            f.write(f\">{fam}_sample_{i+1}\\n{seq}\\n\")\n\nprint(\"âœ… Sequences saved to 'generated_sequences.fasta'\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}